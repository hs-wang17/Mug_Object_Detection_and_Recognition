{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e19c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fdad05",
   "metadata": {},
   "source": [
    "# 读取数据\n",
    "数据来源：scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0012563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5277ecfc8f884a7b83acfcf4c3736a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cc7346ef6540e395c3cfd37b009ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "for pic in tqdm(os.listdir('scene')):\n",
    "    pic_path = './scene/' + pic\n",
    "    # 读取RGB三通道图像(640, 640, 3)\n",
    "    pic_data = cv2.imread(pic_path, cv2.IMREAD_COLOR)\n",
    "    pic_data = cv2.resize(pic_data, (224, 224))\n",
    "    x_list.append(pic_data)\n",
    "    y_list.append(int(pic[6:8]))\n",
    "x_list = np.array(x_list)\n",
    "y_list_int = np.array(y_list)\n",
    "\n",
    "scene_label = pd.read_excel('scene_label.xlsx')\n",
    "y_list = np.zeros((y_list_int.shape[0], 20))\n",
    "for i in trange(y_list_int.shape[0]):\n",
    "    y_list[i, scene_label[scene_label.id==y_list_int[i]].iloc[:, 1:].dropna(axis=1).astype(int).to_numpy()[0].tolist()] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebdcad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# 假设标签数据保存在label_list中，其中每个标签是一个整数\n",
    "X = x_list\n",
    "y = y_list\n",
    "\n",
    "# 分层抽样，其中train_size和test_size分别表示训练集和测试集的比例\n",
    "# n_splits表示抽取的次数，random_state表示随机数种子\n",
    "split = StratifiedShuffleSplit(n_splits=1, train_size=0.8, test_size=0.2, random_state=42)\n",
    "train_index, test_index = next(split.split(X, y))\n",
    "\n",
    "# 得到训练集和测试集\n",
    "X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "\n",
    "# 将训练集进一步划分为训练集和验证集，其中test_size表示验证集的比例\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_index, valid_index = next(split.split(X_train, y_train))\n",
    "\n",
    "# 得到训练集、验证集和测试集的索引\n",
    "train_index = [train_index[i] for i in range(len(train_index))]\n",
    "valid_index = [valid_index[i] for i in range(len(valid_index))]\n",
    "test_index = [test_index[i] for i in range(len(test_index))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff96fb06",
   "metadata": {},
   "source": [
    "# 分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf3eb630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "# 定义超参数\n",
    "batch_size = 8\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 100\n",
    "\n",
    "# 设置 GPU\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# 加载数据集\n",
    "train_data = x_list[train_index]\n",
    "train_labels = y_list[train_index]\n",
    "valid_data = x_list[valid_index]\n",
    "valid_labels = y_list[valid_index]\n",
    "test_data = x_list[test_index]\n",
    "test_labels = y_list[test_index]\n",
    "\n",
    "# # 定义数据增强和标准化\n",
    "# # 在scene数据集中只做了标准化\n",
    "transform = transforms.Compose([\n",
    "#     transforms.RandomAffine(5),\n",
    "#     transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "#     transforms.RandomCrop((88, 88)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(), # 转换为张量\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # 标准化张量\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "train_dataset = MyDataset(train_data, train_labels, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_dataset = MyDataset(valid_data, valid_labels, transform=transform)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = MyDataset(test_data, test_labels, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e57078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential, Linear\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.vgg16()\n",
    "path = './pretrained_model/vgg16-397923af.pth'\n",
    "trained_state_dict = torch.load(path)\n",
    "model.load_state_dict(trained_state_dict, strict=False)\n",
    "\n",
    "model.classifier[6] = Sequential(Linear(4096, 20))\n",
    "model.classifier\n",
    "model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d293ca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "for epoch in trange(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print('Epoch [%d/%d], Loss: %.4f' % (epoch + 1, num_epochs, epoch_loss))\n",
    "    torch.save(model.state_dict(), \"./classifier/model-VGG16-scene/epoch-%d.pt\" % epoch)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(valid_loader):\n",
    "            inputs, labels = inputs.to(device), labels\n",
    "            outputs = model(inputs)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(valid_dataset)\n",
    "        print('Loss of the model on the valid images: %f' % loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffc828f",
   "metadata": {},
   "source": [
    "# 评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c136e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc5acf4748b49629e1e7a280922457c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "# 测试模型（这里是针对单个杯子设计的准确率，多个杯子需修改代码）\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader):\n",
    "        inputs, labels = inputs.to(device), labels\n",
    "        outputs = model(inputs)\n",
    "        predicted = np.int64(np.array(outputs.data.cpu()) > 0)\n",
    "        y_pred.append(predicted)\n",
    "        y_true.append(np.int64(np.array(labels.cpu())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6943d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.row_stack(y_pred)\n",
    "y_true = np.row_stack(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6af9cf0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multilabel Confusion Matrix:\n",
      "[[[460   0]\n",
      "  [  0  40]]\n",
      "\n",
      " [[360   0]\n",
      "  [  0 140]]\n",
      "\n",
      " [[380   0]\n",
      "  [  0 120]]\n",
      "\n",
      " [[400   0]\n",
      "  [  0 100]]\n",
      "\n",
      " [[400   0]\n",
      "  [  0 100]]\n",
      "\n",
      " [[440   0]\n",
      "  [  0  60]]\n",
      "\n",
      " [[379   1]\n",
      "  [  0 120]]\n",
      "\n",
      " [[300   0]\n",
      "  [  0 200]]\n",
      "\n",
      " [[380   0]\n",
      "  [  0 120]]\n",
      "\n",
      " [[399   1]\n",
      "  [  0 100]]\n",
      "\n",
      " [[380   0]\n",
      "  [  0 120]]\n",
      "\n",
      " [[380   0]\n",
      "  [  0 120]]\n",
      "\n",
      " [[480   0]\n",
      "  [  0  20]]\n",
      "\n",
      " [[440   0]\n",
      "  [  0  60]]\n",
      "\n",
      " [[420   0]\n",
      "  [  0  80]]\n",
      "\n",
      " [[460   0]\n",
      "  [  0  40]]\n",
      "\n",
      " [[400   0]\n",
      "  [  0 100]]\n",
      "\n",
      " [[440   0]\n",
      "  [  0  60]]\n",
      "\n",
      " [[460   0]\n",
      "  [  0  40]]\n",
      "\n",
      " [[420   0]\n",
      "  [  0  80]]]\n",
      "Precision: 0.9989023051591658\n",
      "Recall: 1.0\n",
      "F1 Score: 0.99945085118067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# 计算混淆矩阵\n",
    "mcm = multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# 计算精确度、召回率和F1分数\n",
    "precision = precision_score(y_true, y_pred, average='micro')\n",
    "recall = recall_score(y_true, y_pred, average='micro')\n",
    "f1 = f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "# 打印结果\n",
    "print(\"Multilabel Confusion Matrix:\")\n",
    "print(mcm)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb9fe8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
